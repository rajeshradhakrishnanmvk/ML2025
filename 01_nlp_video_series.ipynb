{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_nlp_video_series.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuYa5r1Br/cVumprdBqsM4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAu9jk6uC0x2"
      },
      "source": [
        "# NLP - Malayalam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYU2TGmeC5xB"
      },
      "source": [
        "%%capture\n",
        "!pip install -qq transformers transformers['sentencepiece'] torch torchaudio pydub soundfile datasets jiwer wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0y_ecWUDLRA"
      },
      "source": [
        "import transformers\n",
        "import torchaudio\n",
        "import torch\n",
        "import IPython\n",
        "from pydub import AudioSegment\n",
        "import ipywidgets as widgets\n",
        "from transformers import  Wav2Vec2Processor,Wav2Vec2ForCTC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCDBr_0xDL9n"
      },
      "source": [
        "uploader = widgets.FileUpload(description=\"Audio Upload\", accept='.wav', multiple=False)\n",
        "uploader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYjoP80WDOou"
      },
      "source": [
        "with open(list(uploader.value.keys())[0], \"w+b\") as i:\n",
        "    i.write(uploader.data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-N4gmtCDVpw"
      },
      "source": [
        "audio_filename = uploader.data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2FebReqDS5w"
      },
      "source": [
        "import soundfile as sf\n",
        "data, samplerate = sf.read(audio_filename)\n",
        "data, samplerate\n",
        "# sf.write('newSpeech.wav', uploader.data[0], 16000)\n",
        "IPython.display.Audio(audio_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "287e8jdTDy4u"
      },
      "source": [
        "## Malayalam - Speech to Text Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8uxPSCVDu_A"
      },
      "source": [
        "processor = Wav2Vec2Processor.from_pretrained(\"gvs/wav2vec2-large-xlsr-malayalam\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"gvs/wav2vec2-large-xlsr-malayalam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRoc5QMkD3d4"
      },
      "source": [
        "batch = {\n",
        "         \"path\":'/content/' + audio_filename\n",
        "        }\n",
        "\n",
        "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
        "\n",
        "def speech_file_to_array_fn(batch):\n",
        "  speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
        "  batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
        "  return batch\n",
        "\n",
        "input_voice = speech_file_to_array_fn(batch)[\"speech\"]#[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3R4xHW7D__B"
      },
      "source": [
        "inputs = processor(input_voice, sampling_rate=16_000, return_tensors=\"pt\", padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b27BDsmsEJif"
      },
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "  #logits = model(torch.squeeze(inputs.input_values), attention_mask=inputs.attention_mask).logits\n",
        "\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "print(\"Prediction:\", processor.batch_decode(predicted_ids))\n",
        "#print(\"Reference:\", test_dataset[\"sentence\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUYMzJW_DCdY"
      },
      "source": [
        "# References:\n",
        "\n",
        "* Fine-tuning XLSR-Wav2Vec2 for Multi-Lingual ASR with ðŸ¤— Transformers\n",
        "\n",
        "  https://github.com/gauthamsuresh09/wav2vec2-large-xlsr-53-malayalam/blob/main/fine-tune-xlsr-wav2vec2-on-malayalam-asr-with-transformers_v2.ipynb\n",
        "\n",
        "\n",
        "* gvs/wav2vec2-large-xlsr-malayalam\n",
        "\n",
        "  https://huggingface.co/gvs/wav2vec2-large-xlsr-malayalam\n",
        "  \n",
        "  https://github.com/gauthamsuresh09/wav2vec2-large-xlsr-53-malayalam/blob/main/make_hf_dataset.ipynb\n",
        "  \n",
        "  https://github.com/gauthamsuresh09/wav2vec2-large-xlsr-53-malayalam/blob/main/fine-tune-xlsr-wav2vec2-on-malayalam-asr-with-transformers_v2.ipynb\n",
        "\n",
        "* Kaggle Dataset\n",
        "\n",
        "  https://www.kaggle.com/kavyamanohar/indic-tts-malayalam-speech-corpus\n",
        "\n",
        "* Ramayanam\n",
        "\n",
        "  https://www.youtube.com/playlist?list=PLSU-mNMlRpjS6uDTWFyhMXbKm-_JXi14W\n",
        "\n",
        "* Audio/Video\n",
        "\n",
        "  https://nbviewer.jupyter.org/github/rajeshradhakrishnanmvk/kitchenpy/blob/master/00_core.ipynb\n",
        "\n",
        "* https://huggingface.co/gvs/wav2vec2-large-xlsr-malayalam\n",
        "\n",
        "* Rachel Thomas (NLP Course)\n",
        "\n",
        "  https://www.youtube.com/watch?v=tG3pUwmGjsc&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=2\n",
        "\n",
        "* Contradictory, My Dear Watson\n",
        "  https://www.kaggle.com/rajeshradhakrishnan/raj-contradictory-my-dear-watson\n",
        "\n",
        "* fastai, Huggingface & Weights and Bias\n",
        "  \n",
        "  [Lecture - 1 Colab](https://colab.research.google.com/gist/ohmeow/d5a35fc237fd416ddba3ac82dca38bd5/fastai-huggingface-session-1-transformers-what-can-they-do.ipynb)\n",
        "  \n",
        "  [Lecture - 2 Colab](https://colab.research.google.com/gist/ohmeow/db9071ecf96e867a6f67349162ad1ab6/fastai-huggingface-session-2-using-transformers.ipynb)\n",
        "\n",
        "* Language Model Zoo\n",
        "\n",
        "    https://forums.fast.ai/t/language-model-zoo-gorilla/14623\n",
        "    \n",
        "    https://github.com/goru001/nlp-for-malyalam\n",
        "    \n",
        "    https://github.com/qburst/common-crawl-malayalam\n",
        "    \n",
        "    https://forums.fast.ai/t/language-models-for-multiple-languages/14517/10\n",
        "\n",
        "    https://github.com/google/sentencepiece\n",
        "\n",
        "    https://github.com/goru001/nlp-for-malyalam/blob/master/language-model/Malyalam_Language_Model_ULMFiT.ipynb\n",
        "\n",
        "    https://github.com/goru001/inltk\n",
        "\n",
        "* Books\n",
        "\n",
        "  [Natural Language Processing with Python](https://www.nltk.org/book/)\n",
        "\n",
        "  [Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/information-retrieval-book.html)\n",
        "\n",
        "* Productionize \n",
        "\n",
        "  [Dockerize Hugging Face](https://github.com/AbinayaM02/HFServing)\n",
        "\n",
        "  [Heroku api] (https://huggingface-raj.herokuapp.com/api/get-classify)\n"
      ]
    }
  ]
}